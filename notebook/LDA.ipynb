{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open CSV file of the data\n",
    "data = pd.read_csv('normalized_trainingdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>392</td>\n",
       "      <td>903507</td>\n",
       "      <td>-0.239005</td>\n",
       "      <td>0.438392</td>\n",
       "      <td>-0.263563</td>\n",
       "      <td>-0.233494</td>\n",
       "      <td>1.227238</td>\n",
       "      <td>-0.550261</td>\n",
       "      <td>-0.745273</td>\n",
       "      <td>-0.592632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145558</td>\n",
       "      <td>-0.428577</td>\n",
       "      <td>-0.349350</td>\n",
       "      <td>-0.119256</td>\n",
       "      <td>-0.972078</td>\n",
       "      <td>-0.969862</td>\n",
       "      <td>-0.794466</td>\n",
       "      <td>0.510919</td>\n",
       "      <td>-1.092594</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>871001501</td>\n",
       "      <td>-0.429974</td>\n",
       "      <td>-0.467354</td>\n",
       "      <td>-0.509636</td>\n",
       "      <td>-0.411892</td>\n",
       "      <td>-1.528609</td>\n",
       "      <td>-1.388717</td>\n",
       "      <td>-0.996507</td>\n",
       "      <td>-0.854272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.867471</td>\n",
       "      <td>-0.794639</td>\n",
       "      <td>-0.676082</td>\n",
       "      <td>-2.149090</td>\n",
       "      <td>-1.462664</td>\n",
       "      <td>-1.325090</td>\n",
       "      <td>-1.364965</td>\n",
       "      <td>-1.685291</td>\n",
       "      <td>-1.373434</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117</td>\n",
       "      <td>864729</td>\n",
       "      <td>-0.365432</td>\n",
       "      <td>1.087851</td>\n",
       "      <td>-0.370005</td>\n",
       "      <td>-0.329087</td>\n",
       "      <td>-1.273222</td>\n",
       "      <td>-0.562195</td>\n",
       "      <td>-0.429223</td>\n",
       "      <td>-0.760788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932695</td>\n",
       "      <td>-0.434338</td>\n",
       "      <td>-0.327802</td>\n",
       "      <td>-0.425402</td>\n",
       "      <td>0.629745</td>\n",
       "      <td>0.632887</td>\n",
       "      <td>0.074840</td>\n",
       "      <td>-0.093767</td>\n",
       "      <td>0.636523</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>855133</td>\n",
       "      <td>-0.962562</td>\n",
       "      <td>-0.306445</td>\n",
       "      <td>-0.934186</td>\n",
       "      <td>-0.974342</td>\n",
       "      <td>0.030707</td>\n",
       "      <td>-0.124418</td>\n",
       "      <td>-0.453006</td>\n",
       "      <td>-0.553292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244852</td>\n",
       "      <td>-1.029215</td>\n",
       "      <td>-1.107727</td>\n",
       "      <td>0.448613</td>\n",
       "      <td>0.022443</td>\n",
       "      <td>-0.241771</td>\n",
       "      <td>-0.226426</td>\n",
       "      <td>-1.003151</td>\n",
       "      <td>-0.074812</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>319</td>\n",
       "      <td>894335</td>\n",
       "      <td>-0.579481</td>\n",
       "      <td>1.836321</td>\n",
       "      <td>-0.605254</td>\n",
       "      <td>-0.571640</td>\n",
       "      <td>-0.880673</td>\n",
       "      <td>-0.777957</td>\n",
       "      <td>-0.618262</td>\n",
       "      <td>-0.786001</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724364</td>\n",
       "      <td>-0.656453</td>\n",
       "      <td>-0.648614</td>\n",
       "      <td>-0.508829</td>\n",
       "      <td>-0.425796</td>\n",
       "      <td>-0.407535</td>\n",
       "      <td>-0.662139</td>\n",
       "      <td>-0.731524</td>\n",
       "      <td>-0.120822</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0         392     903507    -0.239005      0.438392       -0.263563   \n",
       "1         150  871001501    -0.429974     -0.467354       -0.509636   \n",
       "2         117     864729    -0.365432      1.087851       -0.370005   \n",
       "3          38     855133    -0.962562     -0.306445       -0.934186   \n",
       "4         319     894335    -0.579481      1.836321       -0.605254   \n",
       "\n",
       "   area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0  -0.233494         1.227238         -0.550261       -0.745273   \n",
       "1  -0.411892        -1.528609         -1.388717       -0.996507   \n",
       "2  -0.329087        -1.273222         -0.562195       -0.429223   \n",
       "3  -0.974342         0.030707         -0.124418       -0.453006   \n",
       "4  -0.571640        -0.880673         -0.777957       -0.618262   \n",
       "\n",
       "   concave_points_mean    ...      texture_worst  perimeter_worst  area_worst  \\\n",
       "0            -0.592632    ...          -0.145558        -0.428577   -0.349350   \n",
       "1            -0.854272    ...          -0.867471        -0.794639   -0.676082   \n",
       "2            -0.760788    ...           0.932695        -0.434338   -0.327802   \n",
       "3            -0.553292    ...           0.244852        -1.029215   -1.107727   \n",
       "4            -0.786001    ...           1.724364        -0.656453   -0.648614   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n",
       "0         -0.119256          -0.972078        -0.969862             -0.794466   \n",
       "1         -2.149090          -1.462664        -1.325090             -1.364965   \n",
       "2         -0.425402           0.629745         0.632887              0.074840   \n",
       "3          0.448613           0.022443        -0.241771             -0.226426   \n",
       "4         -0.508829          -0.425796        -0.407535             -0.662139   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0        0.510919                -1.092594          M  \n",
       "1       -1.685291                -1.373434          B  \n",
       "2       -0.093767                 0.636523          M  \n",
       "3       -1.003151                -0.074812          M  \n",
       "4       -0.731524                -0.120822          B  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target value to categorical data\n",
    "#diagnosis_cat = data.diagnosis.astype('category')\n",
    "#print(diagnosis_cat.cat.category)\n",
    "\n",
    "# Change to data.diagnosis_cat.cat.codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2: Convert target value to categorical data\n",
    "#from sklearn import preprocessing\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#le.fit([\"M\", \"B\"])\n",
    "#LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import LDA from sklearn\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "\n",
    "# Info: http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "# First paper on using LDA in biology: http://www.jstor.org/stable/2983775?seq=1#page_scan_tab_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'symmetry_worst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1cd6f2a3b651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'fractal_dimension_worst'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    541\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'symmetry_worst'"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "lda = LinearDiscriminantAnalysis() #default solver is single value decomposition, no shrinkage\n",
    "\n",
    "y_train = data['diagnosis']\n",
    "y_train=y_train.map({'B': 0,'M': 1})\n",
    "x_train = data.columns.drop(['Unnamed: 0','id','diagnosis'])\n",
    "\n",
    "model = lda.fit(x_train, y_train) #Error: 'could not convert string to float', on several variables...\n",
    "print(model.priors_)\n",
    "print(model.means_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'symmetry_worst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8410f3e42377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fit the scaled data to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpca_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create a new dataframe to store PC's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \"\"\"\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 366\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                       force_all_finite)\n\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'symmetry_worst'"
     ]
    }
   ],
   "source": [
    "# Make PCDA - principcal component discriminant analysis which is more robust\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create new PCA model (Use 2 components)\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "# Fit the scaled data to the model\n",
    "pca_fitted = pca.fit_transform(x_train)\n",
    "\n",
    "# Create a new dataframe to store PC's\n",
    "pca_df = pd.DataFrame(data = pca_fitted, columns = ['PC1', 'PC2'])\n",
    "\n",
    "# Add class information as a column identifier\n",
    "pca_df['diagnosis'] = data_train.diagnosis.values\n",
    "\n",
    "# Print the explain variance calculated\n",
    "print(\"PC1 explains: \", pca.explained_variance_ratio_[0] * 100, \"%\")\n",
    "print(\"PC2 explains: \", pca.explained_variance_ratio_[1] * 100, \"%\")\n",
    "pc1_axis = round(pca.explained_variance_ratio_[0] * 100, 1)\n",
    "pc2_axis = round(pca.explained_variance_ratio_[1] * 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform cross validation on PCA to determine number of PC's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform LDA on PC's - output is discriminant vector with length of number of PC's"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
